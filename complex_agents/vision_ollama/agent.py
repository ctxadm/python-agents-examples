#!/usr/bin/env python3
"""
Vision Agent fÃ¼r LiveKit Multi-Agent System
Kompatibel mit LiveKit Agents 1.0.23 (NEUE API)
Pfad: python-agents/complex-agents/vision_ollama/agent.py
"""

import asyncio
import logging
import os
from typing import Optional

from livekit import rtc
from livekit.agents import JobContext, get_job_context
from livekit.agents.llm import ChatContext, ChatMessage, ImageContent
from livekit.agents.voice import Agent, AgentSession
from livekit.plugins import openai, silero

# Setup logging
logger = logging.getLogger("vision-agent")
logger.setLevel(logging.INFO)

# Environment variables
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://172.16.0.136:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llava-llama3:latest")


class VisionAgent(Agent):
    """Vision-enabled agent for code analysis"""
    
    def __init__(self) -> None:
        self._latest_frame: Optional[rtc.VideoFrame] = None
        self._video_stream: Optional[rtc.VideoStream] = None
        self._frame_task: Optional[asyncio.Task] = None
        
        # Initialize parent class with configuration
        super().__init__(
            instructions="""Du bist ein Code-Analyse-Spezialist mit Vision-FÃ¤higkeiten.
            Du kannst sehen was der User dir Ã¼ber die Kamera zeigt.
            
            WICHTIGE REGELN:
            - Antworte IMMER auf Deutsch
            - Wenn du Code siehst, analysiere ihn genau
            - Finde Syntax-Fehler und nenne die Zeilennummer
            - Gib konkrete Korrekturen
            - Halte Antworten kurz und prÃ¤zise (max 2-3 SÃ¤tze)
            
            Wenn der User sagt "Siehst du meinen Code?" oder "Kannst du das Bild sehen?", 
            dann bestÃ¤tige dass du das Bild siehst und beschreibe was du siehst.""",
            
            stt=openai.STT(
                model="whisper-1",
                language="de"
            ),
            
            llm=openai.LLM.with_ollama(
                model=OLLAMA_MODEL,
                base_url=f"{OLLAMA_HOST}/v1",
                temperature=0.0
            ),
            
            tts=openai.TTS(
                model="tts-1",
                voice="nova",
                speed=1.0
            ),
            
            vad=silero.VAD.load(
                min_speech_duration=0.2,
                min_silence_duration=0.5
            )
        )
        
        logger.info(f"âœ… VisionAgent initialized with Ollama at {OLLAMA_HOST}")
    
    async def on_enter(self) -> None:
        """Called when agent enters the room"""
        logger.info("ğŸšª Agent entering room - on_enter called")
        
        try:
            room = get_job_context().room
            logger.info(f"ğŸ“ Room name: {room.name}")
            logger.info(f"ğŸ‘¥ Remote participants: {len(room.remote_participants)}")
            
            # Check for existing video tracks
            video_track_found = False
            for participant in room.remote_participants.values():
                logger.info(f"ğŸ‘¤ Checking participant: {participant.identity}")
                
                for publication in participant.track_publications.values():
                    if publication.track and publication.track.kind == rtc.TrackKind.KIND_VIDEO:
                        if publication.subscribed:
                            logger.info(f"ğŸ“¹ Found subscribed video track from {participant.identity}")
                            self._setup_video_stream(publication.track)
                            video_track_found = True
                            break
                        else:
                            logger.info(f"ğŸ“¹ Found unsubscribed video track from {participant.identity}")
                
                if video_track_found:
                    break
            
            if not video_track_found:
                logger.warning("âš ï¸ No video tracks found on enter")
            
            # Listen for new tracks
            @room.on("track_subscribed")
            def on_track_subscribed(
                track: rtc.Track,
                publication: rtc.RemoteTrackPublication,
                participant: rtc.RemoteParticipant
            ):
                logger.info(f"ğŸ¬ track_subscribed event: {track.kind} from {participant.identity}")
                if track.kind == rtc.TrackKind.KIND_VIDEO:
                    logger.info(f"ğŸ“¹ New video track subscribed from {participant.identity}")
                    self._setup_video_stream(track)
            
            # Listen for track unsubscribed
            @room.on("track_unsubscribed")
            def on_track_unsubscribed(
                track: rtc.Track,
                publication: rtc.RemoteTrackPublication,
                participant: rtc.RemoteParticipant
            ):
                if track.kind == rtc.TrackKind.KIND_VIDEO:
                    logger.info(f"ğŸ“¹ Video track unsubscribed from {participant.identity}")
                    self._cleanup_video_stream()
                    
        except Exception as e:
            logger.error(f"âŒ Error in on_enter: {e}", exc_info=True)
    
    async def on_user_turn_completed(
        self, 
        turn_ctx: ChatContext, 
        new_message: ChatMessage
    ) -> None:
        """Attach video frame to user's message"""
        logger.info("ğŸ’¬ on_user_turn_completed called")
        logger.info(f"ğŸ“ User message: {new_message.content}")
        
        if self._latest_frame:
            logger.info("ğŸ“¸ Attaching video frame to message")
            
            try:
                # Create image content from frame
                image_content = ImageContent(image=self._latest_frame)
                new_message.content.append(image_content)
                
                # Clear frame after use
                self._latest_frame = None
                logger.info("âœ… Frame attached successfully to user message")
            except Exception as e:
                logger.error(f"âŒ Error attaching frame: {e}", exc_info=True)
        else:
            logger.warning("âš ï¸ No video frame available for attachment")
    
    def _setup_video_stream(self, track: rtc.Track) -> None:
        """Setup video stream from track"""
        try:
            logger.info("ğŸ¥ Setting up video stream...")
            
            # Cleanup existing stream
            self._cleanup_video_stream()
            
            # Create new video stream
            self._video_stream = rtc.VideoStream(track)
            logger.info("ğŸ“¹ Video stream created successfully")
            
            # Start frame capture task
            self._frame_task = asyncio.create_task(self._capture_frames())
            logger.info("ğŸš€ Frame capture task started")
            
        except Exception as e:
            logger.error(f"âŒ Error setting up video stream: {e}", exc_info=True)
    
    def _cleanup_video_stream(self) -> None:
        """Cleanup video stream and tasks"""
        logger.info("ğŸ§¹ Cleaning up video stream...")
        
        if self._frame_task and not self._frame_task.done():
            self._frame_task.cancel()
            self._frame_task = None
            logger.info("âœ… Frame task cancelled")
        
        if self._video_stream:
            try:
                # Note: close() might not exist in some versions
                if hasattr(self._video_stream, 'close'):
                    self._video_stream.close()
            except Exception as e:
                logger.warning(f"âš ï¸ Error closing video stream: {e}")
            self._video_stream = None
            logger.info("âœ… Video stream cleaned up")
    
    async def _capture_frames(self) -> None:
        """Capture frames from video stream"""
        frame_count = 0
        
        try:
            logger.info("ğŸ¥ Starting frame capture loop")
            
            async for event in self._video_stream:
                if hasattr(event, 'frame'):
                    self._latest_frame = event.frame
                    frame_count += 1
                    
                    # Log progress every 30 frames (~1 second)
                    if frame_count % 30 == 0:
                        logger.info(f"ğŸ“¸ Captured {frame_count} frames")
                    
                    # Log first frame
                    if frame_count == 1:
                        logger.info("ğŸ‰ First frame captured successfully!")
                        
        except asyncio.CancelledError:
            logger.info(f"ğŸ›‘ Frame capture cancelled after {frame_count} frames")
        except Exception as e:
            logger.error(f"âŒ Error capturing frames: {e}", exc_info=True)


async def entrypoint(ctx: JobContext) -> None:
    """Main entrypoint for the vision agent"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Vision Agent Starting (LiveKit Agents 1.0.23)")
    logger.info(f"ğŸ“ Room: {ctx.room.name if ctx.room else 'Unknown'}")
    logger.info(f"ğŸ–¥ï¸ Ollama: {OLLAMA_HOST}")
    logger.info(f"ğŸ¤– Model: {OLLAMA_MODEL}")
    logger.info("=" * 60)
    
    try:
        # Create agent
        agent = VisionAgent()
        logger.info("âœ… Agent instance created")
        
        # Create session
        session = AgentSession()
        logger.info("âœ… AgentSession created")
        
        # Start the session
        logger.info("ğŸš€ Starting agent session...")
        await session.start(
            agent=agent,
            room=ctx.room
        )
        
        logger.info("âœ… Vision agent session started successfully")
        # Session manages its own lifecycle - no need to wait
        
    except Exception as e:
        logger.error(f"âŒ Error in entrypoint: {e}", exc_info=True)
        raise


# For testing as standalone
if __name__ == "__main__":
    from livekit.agents import JobRequest, WorkerOptions
    
    async def request_handler(request: JobRequest) -> None:
        """Accept vision room requests"""
        room_name = request.room.name if request.room else "unknown"
        logger.info(f"ğŸ“¥ Request for room: {room_name}")
        
        if room_name.startswith("vision_room_"):
            logger.info(f"âœ… Accepting vision room: {room_name}")
            await request.accept()
        else:
            logger.info(f"âŒ Rejecting non-vision room: {room_name}")
            await request.reject()
    
    logger.info("ğŸ Starting Vision Agent Worker (Standalone Mode)")
    logger.info(f"ğŸ–¥ï¸ Ollama: {OLLAMA_HOST}")
    logger.info(f"ğŸ¤– Model: {OLLAMA_MODEL}")
    
    cli.run_app(WorkerOptions(
        entrypoint_fnc=entrypoint,
        request_fnc=request_handler
    ))
